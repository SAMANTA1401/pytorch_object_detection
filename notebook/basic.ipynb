{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning is a branch of Machine Learning where algorithms are written that mimic the functioning of a human brain. The most commonly used libraries in deep learning are Tensorflow and PyTorch. Pytorch is an open-source deep learning framework available with a Python and C++ interface. The PyTorch resides inside the torch module. In PyTorch, the data that has to be processed is input in the form of a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to install cuda library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows 11 x86_64: \n",
    "\n",
    "# https://developer.nvidia.com/cuda-downloads?target_os=Windows&target_arch=x86_64&target_version=11&target_type=exe_local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux Ubuntu 24.04 arm64-sbsa :\n",
    "\n",
    "# wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/sbsa/cuda-ubuntu2404.pin\n",
    "# sudo mv cuda-ubuntu2404.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
    "# wget https://developer.download.nvidia.com/compute/cuda/12.6.3/local_installers/cuda-repo-ubuntu2404-12-6-local_12.6.3-560.35.05-1_arm64.deb\n",
    "# sudo dpkg -i cuda-repo-ubuntu2404-12-6-local_12.6.3-560.35.05-1_arm64.deb\n",
    "# sudo cp /var/cuda-repo-ubuntu2404-12-6-local/cuda-*-keyring.gpg /usr/share/keyrings/\n",
    "# sudo apt-get update\n",
    "# sudo apt-get -y install cuda-toolkit-12-6\n",
    "\n",
    "# sudo apt-get install -y cuda-drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Check available devices\n",
    "print(torch.cuda.device_count())  # Number of GPUs\n",
    "# print(torch.cuda.current_device())  # Current GPU ID\n",
    "# print(torch.cuda.device(torch.cuda.current_device()))  # Current GPU properties\n",
    "\n",
    "# Check CPU\n",
    "print(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU (if available)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to CPU\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move tensors to GPU\n",
    "data = torch.randn(3, 3)  # Example tensor  multi-dimensional array similar to NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0922,  2.2213,  1.2276],\n",
       "        [ 0.7965, -0.9639,  0.0869],\n",
       "        [-0.8715, -1.3944,  0.1125]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of values to be stored as tensor\n",
    "data1 = [1, 2, 3, 4, 5, 6]\n",
    "data2 = np.array([1.5, 3.4, 6.8,\n",
    "                9.3, 7.0, 2.8])\n",
    " \n",
    "# creating tensors and printing \n",
    "t1 = torch.tensor(data1)\n",
    "t2 = torch.Tensor(data1)\n",
    "t3 = torch.as_tensor(data2)\n",
    "t4 = torch.from_numpy(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_16884\\1322002895.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  d_tensor = torch.tensor(data) # Example\n"
     ]
    }
   ],
   "source": [
    "d_tensor = torch.tensor(data) # Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0922,  2.2213,  1.2276],\n",
       "        [ 0.7965, -0.9639,  0.0869],\n",
       "        [-0.8715, -1.3944,  0.1125]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0922,  2.2213,  1.2276],\n",
       "        [ 0.7965, -0.9639,  0.0869],\n",
       "        [-0.8715, -1.3944,  0.1125]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + 2  # broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y * 3 # broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 12, 15])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization:\n",
    "# The __init__ method is the constructor of the class, which is called when an instance of the class is created.\n",
    "# Super Function:\n",
    "# The super(SimpleNN, self).__init__() line calls the constructor of the parent class (nn.Module) to ensure proper initialization.\n",
    "# Defining a Linear Layer:\n",
    "# The self.fc1 = nn.Linear(10, 5) line defines a linear (fully connected) layer with the following properties:\n",
    "# 10 is the number of input features.\n",
    "# 5 is the number of output features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):  # constructor,  A constructor is a special method in a class that is automatically called when an \n",
    "        # object of that class is created. It is used to initialize the attributes of the class.\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)  # atributes\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = SimpleNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNN(\n",
       "  (fc1): Linear(in_features=10, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN.fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=5, bias=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7969,  0.3970, -0.5916,  0.3226, -0.4522,  1.6186,  0.4672,  0.1621,\n",
       "         -1.2545,  0.0917],\n",
       "        [-0.2732,  0.2622,  0.2583, -1.1032, -1.3730,  0.2344, -0.0325,  0.1791,\n",
       "         -0.0940,  0.3402],\n",
       "        [ 0.2753,  0.7800,  0.1288, -1.3370, -0.6918,  0.5433,  0.1228,  0.7991,\n",
       "         -0.1958,  1.1173]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add a method to a class explicitly using the following approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):  # method\n",
    "        return self.fc1(x)\n",
    "\n",
    "setattr(SimpleNN, \"forward\", forward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4305,  0.2883, -0.0256, -0.8229, -0.2528],\n",
       "        [-0.1999, -0.1669, -0.2008, -0.5687, -0.4268],\n",
       "        [-0.0696, -0.0399, -0.3899, -0.1732, -0.6606]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.forward(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decorator  \n",
    "\n",
    "decorator is a design pattern in Python that allows you to wrap another function or class in order to extend its behavior without permanently modifying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decorator(func):\n",
    "#     def wrapper(*args, **kwargs):\n",
    "#         # Code to be executed before the original function\n",
    "#         result = func(*args, **kwargs)\n",
    "#         # Code to be executed after the original function\n",
    "#         return result\n",
    "#     return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_method(cls):\n",
    "    def decorator(func):\n",
    "        setattr(cls, func.__name__, func)\n",
    "        return func\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yield > generator  Generators are a type of iterable, like lists or tuples. However, unlike lists, \n",
    "# generators do not store all the values in memory, instead, they generate the values on-the-fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_method(SimpleNN)\n",
    "def custom_forward(self, x):\n",
    "    return torch.relu(self.fc1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.2883, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.custom_forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something is happening before the function is called.\n",
      "Hello!\n",
      "Something is happening after the function is called.\n"
     ]
    }
   ],
   "source": [
    "def my_decorator(func):\n",
    "    def wrapper():\n",
    "        print(\"Something is happening before the function is called.\")\n",
    "        func()\n",
    "        print(\"Something is happening after the function is called.\")\n",
    "    return wrapper\n",
    "\n",
    "@my_decorator\n",
    "def say_hello():\n",
    "    print(\"Hello!\")\n",
    "\n",
    "say_hello()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threading\n",
    "\n",
    "Threading is a way to achieve concurrency in Python, allowing multiple threads to run concurrently within a single process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is Threading in CPU?\n",
    "# Threading in CPU refers to the ability of a central processing unit (CPU) to execute multiple threads or flows of instructions concurrently, improving overall system performance and responsiveness.\n",
    "# Types of Threading in CPU\n",
    "# Simultaneous Multithreading (SMT): SMT allows multiple threads to share the same physical core, improving resource utilization.\n",
    "# Multi-Threading: Multi-threading allows a single core to execute multiple threads, improving responsiveness and system utilization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "a\n",
      "1\n",
      "b\n",
      "2\n",
      "c\n",
      "3\n",
      "d\n",
      "4\n",
      "e\n",
      "5\n",
      "f\n",
      "6\n",
      "g\n",
      "7\n",
      "h\n",
      "8\n",
      "i\n",
      "9\n",
      "j\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def print_numbers():\n",
    "    for i in range(10):\n",
    "        time.sleep(1)\n",
    "        print(i)\n",
    "\n",
    "def print_letters():\n",
    "    for letter in 'abcdefghij':\n",
    "        time.sleep(1)\n",
    "        print(letter)\n",
    "\n",
    "# Create threads\n",
    "thread1 = threading.Thread(target=print_numbers)\n",
    "thread2 = threading.Thread(target=print_letters)\n",
    "\n",
    "# Start threads\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "# Wait for threads to finish\n",
    "thread1.join()\n",
    "thread2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7969,  0.3970, -0.5916,  0.3226, -0.4522,  1.6186,  0.4672,  0.1621,\n",
       "         -1.2545,  0.0917],\n",
       "        [-0.2732,  0.2622,  0.2583, -1.1032, -1.3730,  0.2344, -0.0325,  0.1791,\n",
       "         -0.0940,  0.3402],\n",
       "        [ 0.2753,  0.7800,  0.1288, -1.3370, -0.6918,  0.5433,  0.1228,  0.7991,\n",
       "         -0.1958,  1.1173]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_input = inputs.reshape(5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\a27_YEARS_OLD\\pytorch\\venv\\Lib\\site-packages\\torch\\_tensor.py:889: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    }
   ],
   "source": [
    "resize_input = reshape_input.resize(6,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7969,  0.3970, -0.5916,  0.3226, -0.4522],\n",
       "        [ 1.6186,  0.4672,  0.1621, -1.2545,  0.0917],\n",
       "        [-0.2732,  0.2622,  0.2583, -1.1032, -1.3730],\n",
       "        [ 0.2344, -0.0325,  0.1791, -0.0940,  0.3402],\n",
       "        [ 0.2753,  0.7800,  0.1288, -1.3370, -0.6918],\n",
       "        [ 0.5433,  0.1228,  0.7991, -0.1958,  1.1173]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7969,  0.3970, -0.5916,  0.3226, -0.4522,  1.6186,  0.4672,  0.1621,\n",
       "         -1.2545,  0.0917],\n",
       "        [-0.2732,  0.2622,  0.2583, -1.1032, -1.3730,  0.2344, -0.0325,  0.1791,\n",
       "         -0.0940,  0.3402],\n",
       "        [ 0.2753,  0.7800,  0.1288, -1.3370, -0.6918,  0.5433,  0.1228,  0.7991,\n",
       "         -0.1958,  1.1173]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does transpose do?\n",
    "# The transpose method in PyTorch swaps the dimensions of a tensor. It takes two arguments, dim0 and dim1, which specify the dimensions to be swapped.\n",
    "# What do the indices (1, 0) mean?\n",
    "# In PyTorch, tensor dimensions are indexed starting from 0. The indices (1, 0) mean:\n",
    "# 0 refers to the first dimension (usually the batch size)\n",
    "# 1 refers to the second dimension (usually row no or sequence length)\n",
    "# What happens when you call inputs.transpose(1, 0)?\n",
    "# When you call inputs.transpose(1, 0), PyTorch swaps the first and second dimensions of the inputs tensor.\n",
    "# Example\n",
    "# Suppose inputs is a tensor with shape (batch_size, sequence_length, embedding_dim), where:\n",
    "# batch_size is the number of samples in the batch 1st axis\n",
    "# sequence_length is the length of each sequence or no of row 2nd axis\n",
    "# column 3rd axis \n",
    "# If inputs has shape (32, 10, 128), calling inputs.transpose(1, 0) would result in a tensor with shape (10, 32, 128)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7969, -0.2732,  0.2753],\n",
       "        [ 0.3970,  0.2622,  0.7800],\n",
       "        [-0.5916,  0.2583,  0.1288],\n",
       "        [ 0.3226, -1.1032, -1.3370],\n",
       "        [-0.4522, -1.3730, -0.6918],\n",
       "        [ 1.6186,  0.2344,  0.5433],\n",
       "        [ 0.4672, -0.0325,  0.1228],\n",
       "        [ 0.1621,  0.1791,  0.7991],\n",
       "        [-1.2545, -0.0940, -0.1958],\n",
       "        [ 0.0917,  0.3402,  1.1173]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.transpose(1 ,0 ) # axis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.transpose(1 ,0 ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7969, -0.2732,  0.2753],\n",
       "        [ 0.3970,  0.2622,  0.7800],\n",
       "        [-0.5916,  0.2583,  0.1288],\n",
       "        [ 0.3226, -1.1032, -1.3370],\n",
       "        [-0.4522, -1.3730, -0.6918],\n",
       "        [ 1.6186,  0.2344,  0.5433],\n",
       "        [ 0.4672, -0.0325,  0.1228],\n",
       "        [ 0.1621,  0.1791,  0.7991],\n",
       "        [-1.2545, -0.0940, -0.1958],\n",
       "        [ 0.0917,  0.3402,  1.1173]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.transpose(0, 1) # axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3d = torch.randn(3, 10 , 5) # no of batch = 3, row in each batch = 10, col in each row = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1404,  1.7859, -0.0808, -0.3776,  0.6276],\n",
       "         [-0.5920, -0.2097,  0.2644, -1.8041, -1.2006],\n",
       "         [ 1.9811,  0.4113, -0.3142,  2.2199, -1.0522],\n",
       "         [ 1.6184, -0.8286, -0.4455, -0.9556,  1.0425],\n",
       "         [-0.7034,  0.1163,  0.1383, -1.1998, -0.2440],\n",
       "         [ 0.2585, -0.1913,  0.3366,  0.4548,  0.4323],\n",
       "         [-2.1225,  0.9055, -2.0818, -0.5666, -0.8725],\n",
       "         [-0.2414,  0.2855, -0.0700,  0.1300,  0.5473],\n",
       "         [-1.0568,  1.6392, -0.8053, -0.6102,  0.7528],\n",
       "         [-0.1919, -1.0545, -1.8967,  0.5810,  0.5674]],\n",
       "\n",
       "        [[ 0.3482,  2.1756,  2.0345,  1.1289,  0.8111],\n",
       "         [-0.3351,  1.1704,  0.2937,  0.9796, -0.7959],\n",
       "         [ 0.8224,  0.3938,  1.0226, -0.4507, -0.3953],\n",
       "         [ 1.1159, -1.3554,  1.3403, -1.1574,  1.6949],\n",
       "         [-0.2567,  0.4700,  0.4530, -1.0499,  2.1902],\n",
       "         [-0.2344,  1.3081, -0.8250, -0.3584, -0.4154],\n",
       "         [-1.0589, -0.9091, -0.2665,  1.1712,  0.9454],\n",
       "         [-1.0306,  0.1125, -1.8777, -1.7650, -1.6328],\n",
       "         [ 1.3953, -0.9257,  0.7415,  0.9343, -1.0410],\n",
       "         [-0.3560,  0.2427,  0.3066, -0.4379,  1.8409]],\n",
       "\n",
       "        [[ 1.1382, -0.6247,  0.4739,  0.0366, -0.3726],\n",
       "         [ 0.1050,  0.1121,  0.4793,  1.5431,  0.5562],\n",
       "         [ 0.0473, -1.2149, -1.8568, -0.1641,  0.6274],\n",
       "         [ 0.7754,  0.1308,  0.3213, -0.0047, -1.6980],\n",
       "         [ 2.0351,  0.4026,  0.3492, -1.6231, -1.0142],\n",
       "         [-1.1630, -0.3773, -1.5198,  0.1174, -0.7055],\n",
       "         [ 0.0976, -0.2051, -1.0362, -0.8668,  1.4311],\n",
       "         [-0.9454,  1.4673, -0.1186,  0.7152, -0.1192],\n",
       "         [ 1.0028,  0.4202,  0.1464,  0.5210,  2.0500],\n",
       "         [-0.5482,  0.0978, -1.4263, -1.7305, -0.1139]]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 5])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1404,  1.7859, -0.0808, -0.3776,  0.6276],\n",
       "         [ 0.3482,  2.1756,  2.0345,  1.1289,  0.8111],\n",
       "         [ 1.1382, -0.6247,  0.4739,  0.0366, -0.3726]],\n",
       "\n",
       "        [[-0.5920, -0.2097,  0.2644, -1.8041, -1.2006],\n",
       "         [-0.3351,  1.1704,  0.2937,  0.9796, -0.7959],\n",
       "         [ 0.1050,  0.1121,  0.4793,  1.5431,  0.5562]],\n",
       "\n",
       "        [[ 1.9811,  0.4113, -0.3142,  2.2199, -1.0522],\n",
       "         [ 0.8224,  0.3938,  1.0226, -0.4507, -0.3953],\n",
       "         [ 0.0473, -1.2149, -1.8568, -0.1641,  0.6274]],\n",
       "\n",
       "        [[ 1.6184, -0.8286, -0.4455, -0.9556,  1.0425],\n",
       "         [ 1.1159, -1.3554,  1.3403, -1.1574,  1.6949],\n",
       "         [ 0.7754,  0.1308,  0.3213, -0.0047, -1.6980]],\n",
       "\n",
       "        [[-0.7034,  0.1163,  0.1383, -1.1998, -0.2440],\n",
       "         [-0.2567,  0.4700,  0.4530, -1.0499,  2.1902],\n",
       "         [ 2.0351,  0.4026,  0.3492, -1.6231, -1.0142]],\n",
       "\n",
       "        [[ 0.2585, -0.1913,  0.3366,  0.4548,  0.4323],\n",
       "         [-0.2344,  1.3081, -0.8250, -0.3584, -0.4154],\n",
       "         [-1.1630, -0.3773, -1.5198,  0.1174, -0.7055]],\n",
       "\n",
       "        [[-2.1225,  0.9055, -2.0818, -0.5666, -0.8725],\n",
       "         [-1.0589, -0.9091, -0.2665,  1.1712,  0.9454],\n",
       "         [ 0.0976, -0.2051, -1.0362, -0.8668,  1.4311]],\n",
       "\n",
       "        [[-0.2414,  0.2855, -0.0700,  0.1300,  0.5473],\n",
       "         [-1.0306,  0.1125, -1.8777, -1.7650, -1.6328],\n",
       "         [-0.9454,  1.4673, -0.1186,  0.7152, -0.1192]],\n",
       "\n",
       "        [[-1.0568,  1.6392, -0.8053, -0.6102,  0.7528],\n",
       "         [ 1.3953, -0.9257,  0.7415,  0.9343, -1.0410],\n",
       "         [ 1.0028,  0.4202,  0.1464,  0.5210,  2.0500]],\n",
       "\n",
       "        [[-0.1919, -1.0545, -1.8967,  0.5810,  0.5674],\n",
       "         [-0.3560,  0.2427,  0.3066, -0.4379,  1.8409],\n",
       "         [-0.5482,  0.0978, -1.4263, -1.7305, -0.1139]]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3d.transpose(0,1)  #  axis batch and row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 5])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3d.transpose(0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1404, -0.5920,  1.9811,  1.6184, -0.7034,  0.2585, -2.1225,\n",
       "          -0.2414, -1.0568, -0.1919],\n",
       "         [ 1.7859, -0.2097,  0.4113, -0.8286,  0.1163, -0.1913,  0.9055,\n",
       "           0.2855,  1.6392, -1.0545],\n",
       "         [-0.0808,  0.2644, -0.3142, -0.4455,  0.1383,  0.3366, -2.0818,\n",
       "          -0.0700, -0.8053, -1.8967],\n",
       "         [-0.3776, -1.8041,  2.2199, -0.9556, -1.1998,  0.4548, -0.5666,\n",
       "           0.1300, -0.6102,  0.5810],\n",
       "         [ 0.6276, -1.2006, -1.0522,  1.0425, -0.2440,  0.4323, -0.8725,\n",
       "           0.5473,  0.7528,  0.5674]],\n",
       "\n",
       "        [[ 0.3482, -0.3351,  0.8224,  1.1159, -0.2567, -0.2344, -1.0589,\n",
       "          -1.0306,  1.3953, -0.3560],\n",
       "         [ 2.1756,  1.1704,  0.3938, -1.3554,  0.4700,  1.3081, -0.9091,\n",
       "           0.1125, -0.9257,  0.2427],\n",
       "         [ 2.0345,  0.2937,  1.0226,  1.3403,  0.4530, -0.8250, -0.2665,\n",
       "          -1.8777,  0.7415,  0.3066],\n",
       "         [ 1.1289,  0.9796, -0.4507, -1.1574, -1.0499, -0.3584,  1.1712,\n",
       "          -1.7650,  0.9343, -0.4379],\n",
       "         [ 0.8111, -0.7959, -0.3953,  1.6949,  2.1902, -0.4154,  0.9454,\n",
       "          -1.6328, -1.0410,  1.8409]],\n",
       "\n",
       "        [[ 1.1382,  0.1050,  0.0473,  0.7754,  2.0351, -1.1630,  0.0976,\n",
       "          -0.9454,  1.0028, -0.5482],\n",
       "         [-0.6247,  0.1121, -1.2149,  0.1308,  0.4026, -0.3773, -0.2051,\n",
       "           1.4673,  0.4202,  0.0978],\n",
       "         [ 0.4739,  0.4793, -1.8568,  0.3213,  0.3492, -1.5198, -1.0362,\n",
       "          -0.1186,  0.1464, -1.4263],\n",
       "         [ 0.0366,  1.5431, -0.1641, -0.0047, -1.6231,  0.1174, -0.8668,\n",
       "           0.7152,  0.5210, -1.7305],\n",
       "         [-0.3726,  0.5562,  0.6274, -1.6980, -1.0142, -0.7055,  1.4311,\n",
       "          -0.1192,  2.0500, -0.1139]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3d.transpose(1,2) # axis row and column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 10])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3d.transpose(1,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_data1 = torch.randn(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3187,  1.4922,  0.3375,  0.3446,  0.7711],\n",
       "        [-0.3616,  0.0701,  0.6352,  0.0218,  0.9515],\n",
       "        [-0.4573, -0.3381,  0.1886, -0.2862, -0.0316]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_data2 = torch.randn(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9052, -0.1994, -0.8003],\n",
       "        [ 0.5386, -0.4892, -0.2091],\n",
       "        [-0.8759, -0.5123, -0.9673],\n",
       "        [-1.5221, -0.1855, -1.5102],\n",
       "        [-0.3614,  0.0030, -1.6511]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2885,  0.8037, -0.2956, -0.5246, -0.2787],\n",
       "        [ 0.0721, -0.0343, -0.3254, -0.0040,  0.0029],\n",
       "        [ 0.3659,  0.0707, -0.1824,  0.4322,  0.0521]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(op_data1,op_data2.T) # elementwise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.5205e-01,  2.7703e+00, -3.8527e-01, -2.2642e-01, -2.1336e+00],\n",
       "        [ 1.8134e+00, -1.4333e-01, -1.2399e+00, -1.1756e-01,  3.1407e+02],\n",
       "        [ 5.7140e-01,  1.6175e+00, -1.9495e-01,  1.8951e-01,  1.9121e-02]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(op_data1,op_data2.T) # elementwise division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5836, -0.9009, -2.1770],\n",
       "        [-1.2230, -0.2887, -1.9437],\n",
       "        [-0.3142,  0.2130,  0.7386]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_data1 @ op_data2 # matrix multiplication 3x5 * 5x3 = 3x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch Modules\n",
    "\n",
    "The PyTorch library modules are essential to create and train neural networks. The three main library modules are Autograd, Optim, and nn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model (nn.Module) : \n",
    "    def __init__(self,x,y): \n",
    "        super(Model, self).__init__()\n",
    "        self.linear = torch.nn.Linear(x, y)  \n",
    " \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd is a reverse automatic differentiation system. Conceptually, autograd records a graph recording all of the operations that created the data as you execute operations, giving you a directed acyclic graph whose leaves are the input tensors and roots are the output tensors. By tracing this graph from roots to leaves, you can automatically compute the gradients using the chain rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved tensors x to compute gradient\n",
    "\n",
    "x = torch.randn(5, requires_grad=True)\n",
    "y = x.pow(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6967,  0.1186, -0.1475, -0.7892, -0.2692], requires_grad=True)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4855, 0.0141, 0.0218, 0.6228, 0.0725], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # y = x^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.grad_fn is the gradient function associated with the computation of y. In this case, since y is computed as the \n",
    "# square of x, the gradient function is an instance of PowBackward.\n",
    "# _saved_self is an attribute of the gradient function that stores the original input tensor x. \n",
    "# This is done to facilitate gradient computation during the backward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equal() method checks whether two tensors have the same shape, size, and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(x.equal(y.grad_fn._saved_self))  # True\n",
    "print(x is y.grad_fn._saved_self)  # True\n",
    "# y.grad_fn._saved_self refers to the same Tensor object as x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in PyTorch, when you compute a new tensor y as a function of an existing tensor x, the resulting tensor y stores \n",
    "# a reference to the original tensor x. This is done to facilitate gradient computation during the backward pass.\n",
    "# In this specific case, since y is computed as the square of x, the resulting tensor y stores a reference to the \n",
    "# original tensor x. Therefore, x and y.grad_fn._saved_self refer to the same object in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5, requires_grad=True)\n",
    "y = x.exp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9626, 0.5535, 2.1479, 0.1702, 1.0008], requires_grad=True)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.6186, 1.7394, 8.5665, 1.1856, 2.7204], grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.grad_fn is the gradient function associated with the computation of y. In this case, since y is computed as the exponential of x, the gradient function is an instance of ExpBackward.\n",
    "# _saved_result is an attribute of the gradient function that stores the result of the forward pass, which is the tensor y itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equal() method checks whether two tensors have the same shape, size, and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(y.equal(y.grad_fn._saved_result))  # True\n",
    "print(y is y.grad_fn._saved_result)  # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although y and y.grad_fn._saved_result have the same values and shape, they are not the same object in memory. This is because PyTorch creates a new tensor object for the result of the forward pass, which is stored in y.grad_fn._saved_result.\n",
    "# In other words, y and y.grad_fn._saved_result are two separate tensor objects that happen to have the same values and shape.\n",
    "# Why does y.equal(y.grad_fn._saved_result) return True?\n",
    "# Although y and y.grad_fn._saved_result are not the same object, they have the same values and shape. Therefore, the equal method returns True, indicating that the two tensors are equal in value, even if they are not the same object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(5, 5, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (x + 3) * (x + 4) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 10., 10., 10., 10.],\n",
       "        [10., 10., 10., 10., 10.],\n",
       "        [10., 10., 10., 10., 10.],\n",
       "        [10., 10., 10., 10., 10.],\n",
       "        [10., 10., 10., 10., 10.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(105.)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a train function to be used in different threads\n",
    "def train_fn():\n",
    "    x = torch.ones(5, 5, requires_grad=True)\n",
    "    print('x',x)\n",
    "    # forward\n",
    "    y = (x + 3) * (x + 4) * 0.5\n",
    "    print('y',y)\n",
    "    # backward\n",
    "    z = y.sum().backward()\n",
    "    # potential optimizer update\n",
    "\n",
    "    print(z)\n",
    "\n",
    "    print('x.grad', x.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a tensor x with shape (5, 5) and requires gradient.\n",
    "# Performs a forward pass by computing y using a simple neural network formula.\n",
    "# Performs a backward pass by computing the gradients of the loss with respect to the inputs using y.sum().backward().\n",
    "# Optionally, an optimizer update can be performed to update the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x x x x x x x x x x "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], requires_grad=True)\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], requires_grad=True)\n",
      "y y tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], requires_grad=True)\n",
      "y tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], requires_grad=True)\n",
      "y tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], requires_grad=True)\n",
      "y tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], requires_grad=True)\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], requires_grad=True)\n",
      "y y tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], requires_grad=True)\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], requires_grad=True)\n",
      "y y tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], requires_grad=True)\n",
      "y tensor([[10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.]], grad_fn=<MulBackward0>)\n",
      "None\n",
      "x.grad tensor([[10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.]], grad_fn=<MulBackward0>)\n",
      "tensor([[10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.]], grad_fn=<MulBackward0>)\n",
      "None\n",
      "x.grad None\n",
      "x.grad tensor([[10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.]], grad_fn=<MulBackward0>)\n",
      "None\n",
      "x.grad tensor([[4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000]])\n",
      "tensor([[10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.]], grad_fn=<MulBackward0>)\n",
      "None\n",
      "x.grad tensor([[10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.]], grad_fn=<MulBackward0>)\n",
      "tensor([[10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.]], grad_fn=<MulBackward0>)\n",
      "None\n",
      "x.grad None\n",
      "x.grad tensor([[10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.]], grad_fn=<MulBackward0>)\n",
      "tensor([[10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.]], grad_fn=<MulBackward0>)\n",
      "tensor([[4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000]])\n",
      "None\n",
      "x.grad tensor([[10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10., 10.]], grad_fn=<MulBackward0>)\n",
      "None\n",
      "x.grad tensor([[4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000]])\n",
      "None\n",
      "x.grad tensor([[4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000]])\n",
      "tensor([[4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000]])\n",
      "tensor([[4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000]])\n",
      "tensor([[4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000]])\n",
      "tensor([[4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000]])\n",
      "tensor([[4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000]])\n",
      "tensor([[4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
      "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "# User write their own threading code to drive the train_fn\n",
    "threads = []\n",
    "for _ in range(10):\n",
    "    p = threading.Thread(target=train_fn, args=())\n",
    "    p.start()\n",
    "    threads.append(p)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an empty list threads to store the thread objects.\n",
    "# Loops 10 times, creating a new thread each time that targets the train_fn function with no arguments.\n",
    "# Starts each thread using the start() method.\n",
    "# Appends each thread object to the threads list.\n",
    "# Loops through the threads list, joining each thread using the join() method. This ensures that the main thread waits for all the child threads to finish before continuing.\n",
    "# What's Happening Under the Hood\n",
    "# When you run this code, the following happens:\n",
    "# The train_fn function is executed in multiple threads, each with its own copy of the tensor x.\n",
    "# Each thread performs the forward and backward passes independently, computing the gradients of the loss with respect to the inputs.\n",
    "# The gradients computed by each thread are accumulated in the x.grad tensor.\n",
    "# Once all threads have finished, the main thread can access the accumulated gradients in x.grad.\n",
    "# Note that this code assumes that the train_fn function is thread-safe, meaning that it does not access any shared resources that could cause conflicts between threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Thread(Thread-349 (train_fn), stopped 6044)>,\n",
       " <Thread(Thread-350 (train_fn), stopped 15656)>,\n",
       " <Thread(Thread-351 (train_fn), stopped 13272)>,\n",
       " <Thread(Thread-352 (train_fn), stopped 6688)>,\n",
       " <Thread(Thread-353 (train_fn), stopped 8640)>,\n",
       " <Thread(Thread-354 (train_fn), stopped 17680)>,\n",
       " <Thread(Thread-355 (train_fn), stopped 6856)>,\n",
       " <Thread(Thread-356 (train_fn), stopped 19548)>,\n",
       " <Thread(Thread-357 (train_fn), stopped 16756)>,\n",
       " <Thread(Thread-358 (train_fn), stopped 19572)>]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in threads:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Neural Network with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainin input(X) and output(y)\n",
    "import torch.nn as nn\n",
    "X = torch.Tensor([[1], [2], [3],\n",
    "                [4], [5], [6]])\n",
    "y = torch.Tensor([[5], [10], [15],\n",
    "                  [20], [25], [30]])\n",
    "\n",
    "# output coresponding 1 is 5\n",
    "# output coresponding 2 is 10\n",
    "# output coresponding 3 is 15\n",
    "# output coresponding 4 is 20\n",
    "# output coresponding 5 is 25\n",
    "# output coresponding 6 is 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    " \n",
    "    # defining layer\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1, 1) \n",
    "     \n",
    "    # implementing forward pass\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model = model.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining loss function and optimizer\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  10 loss:  6.810786724090576\n",
      "epoch:  20 loss:  6.3607869148254395\n",
      "epoch:  30 loss:  5.910787105560303\n",
      "epoch:  40 loss:  5.460788249969482\n",
      "epoch:  50 loss:  5.010788440704346\n",
      "epoch:  60 loss:  4.586870193481445\n",
      "epoch:  70 loss:  4.232003211975098\n",
      "epoch:  80 loss:  3.8901708126068115\n",
      "epoch:  90 loss:  3.5519790649414062\n",
      "epoch:  100 loss:  3.2141811847686768\n",
      "epoch:  110 loss:  2.875676393508911\n",
      "epoch:  120 loss:  2.536119222640991\n",
      "epoch:  130 loss:  2.2020175457000732\n",
      "epoch:  140 loss:  1.970568060874939\n",
      "epoch:  150 loss:  1.7606498003005981\n",
      "epoch:  160 loss:  1.5572971105575562\n",
      "epoch:  170 loss:  1.355275273323059\n",
      "epoch:  180 loss:  1.2316750288009644\n",
      "epoch:  190 loss:  1.1496325731277466\n",
      "epoch:  200 loss:  1.0751460790634155\n",
      "epoch:  210 loss:  1.0027934312820435\n",
      "epoch:  220 loss:  0.986588180065155\n",
      "epoch:  230 loss:  0.9734523892402649\n",
      "epoch:  240 loss:  0.9591490626335144\n",
      "epoch:  250 loss:  0.9443218111991882\n",
      "epoch:  260 loss:  0.9291975498199463\n",
      "epoch:  270 loss:  0.913860023021698\n",
      "epoch:  280 loss:  0.89833664894104\n",
      "epoch:  290 loss:  0.8826408982276917\n",
      "epoch:  300 loss:  0.866777241230011\n",
      "epoch:  310 loss:  0.8510711789131165\n",
      "epoch:  320 loss:  0.8355832099914551\n",
      "epoch:  330 loss:  0.8198005557060242\n",
      "epoch:  340 loss:  0.8040826916694641\n",
      "epoch:  350 loss:  0.787966787815094\n",
      "epoch:  360 loss:  0.7718536853790283\n",
      "epoch:  370 loss:  0.7552346587181091\n",
      "epoch:  380 loss:  0.7389402389526367\n",
      "epoch:  390 loss:  0.7221567034721375\n",
      "epoch:  400 loss:  0.7053326964378357\n",
      "epoch:  410 loss:  0.6884489059448242\n",
      "epoch:  420 loss:  0.6710066795349121\n",
      "epoch:  430 loss:  0.6538206934928894\n",
      "epoch:  440 loss:  0.6362916827201843\n",
      "epoch:  450 loss:  0.6187275052070618\n",
      "epoch:  460 loss:  0.6010537147521973\n",
      "epoch:  470 loss:  0.58320552110672\n",
      "epoch:  480 loss:  0.5651277899742126\n",
      "epoch:  490 loss:  0.5470734238624573\n",
      "epoch:  500 loss:  0.5286538004875183\n",
      "epoch:  510 loss:  0.5102581977844238\n",
      "epoch:  520 loss:  0.4915877878665924\n",
      "epoch:  530 loss:  0.4728463590145111\n",
      "epoch:  540 loss:  0.45404163002967834\n",
      "epoch:  550 loss:  0.435042142868042\n",
      "epoch:  560 loss:  0.41590309143066406\n",
      "epoch:  570 loss:  0.39653077721595764\n",
      "epoch:  580 loss:  0.37710848450660706\n",
      "epoch:  590 loss:  0.35763272643089294\n",
      "epoch:  600 loss:  0.3379671573638916\n",
      "epoch:  610 loss:  0.31810736656188965\n",
      "epoch:  620 loss:  0.2983438968658447\n",
      "epoch:  630 loss:  0.27802643179893494\n",
      "epoch:  640 loss:  0.2578519284725189\n",
      "epoch:  650 loss:  0.23749692738056183\n",
      "epoch:  660 loss:  0.2169404774904251\n",
      "epoch:  670 loss:  0.19635272026062012\n",
      "epoch:  680 loss:  0.17568890750408173\n",
      "epoch:  690 loss:  0.15479731559753418\n",
      "epoch:  700 loss:  0.13372986018657684\n",
      "epoch:  710 loss:  0.11264332383871078\n",
      "epoch:  720 loss:  0.09148605912923813\n",
      "epoch:  730 loss:  0.07010475546121597\n",
      "epoch:  740 loss:  0.04877018928527832\n",
      "epoch:  750 loss:  0.026950201019644737\n",
      "epoch:  760 loss:  0.005711793899536133\n",
      "epoch:  770 loss:  0.0075685977935791016\n",
      "epoch:  780 loss:  0.0034942626953125\n",
      "epoch:  790 loss:  0.005956172943115234\n",
      "epoch:  800 loss:  0.002315123798325658\n",
      "epoch:  810 loss:  0.009281952865421772\n",
      "epoch:  820 loss:  0.0019920666236430407\n",
      "epoch:  830 loss:  0.002753813983872533\n",
      "epoch:  840 loss:  0.0013928413391113281\n",
      "epoch:  850 loss:  0.013389110565185547\n",
      "epoch:  860 loss:  0.0045818486250936985\n",
      "epoch:  870 loss:  0.00912435818463564\n",
      "epoch:  880 loss:  0.0038626987952739\n",
      "epoch:  890 loss:  0.001271327375434339\n",
      "epoch:  900 loss:  0.001831611036323011\n",
      "epoch:  910 loss:  0.012188434600830078\n",
      "epoch:  920 loss:  0.004271427635103464\n",
      "epoch:  930 loss:  0.008468151092529297\n",
      "epoch:  940 loss:  0.0036252338904887438\n",
      "epoch:  950 loss:  0.0012175241718068719\n",
      "epoch:  960 loss:  0.0016899904003366828\n",
      "epoch:  970 loss:  0.011484702117741108\n",
      "epoch:  980 loss:  0.003995100501924753\n",
      "epoch:  990 loss:  0.007970650680363178\n",
      "epoch:  1000 loss:  0.0034553210716694593\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    \n",
    "    # predicting y using initial weights\n",
    "    y_pred = lin_model(X.requires_grad_())\n",
    "    #X is the input data, and requires_grad_() sets the requires_grad attribute of X to True. \n",
    "    # This is necessary because the model's weights need to be updated based on the gradients computed during \n",
    "    # backpropagation.\n",
    " \n",
    "    # loss calculation\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    #loss_fn is the loss function used to evaluate the model's performance. In this case, it's likely \n",
    "    # the mean squared error (MSE) loss function.\n",
    " \n",
    "    # calculating gradients\n",
    "    loss.backward()\n",
    "    #backward() is a PyTorch method that computes the gradients of the loss with respect to the model's parameters.\n",
    "    # The gradients are stored in the grad attribute of each parameter.\n",
    " \n",
    "    # updating weights\n",
    "    optimizer.step()\n",
    "    #optimizer is an instance of PyTorch's Optimizer, which updates the model's parameters based on the gradients \n",
    "    # computed during backpropagation.\n",
    "    # step() updates the parameters using the gradients and the optimizer's hyperparameters (e.g., learning rate).\n",
    " \n",
    "    optimizer.zero_grad()\n",
    "    #zero_grad() sets the gradients of all parameters to zero.\n",
    "    # This is necessary because PyTorch accumulates gradients by default. If we don't zero the gradients, \n",
    "    # they will be added to the gradients computed in the next iteration, leading to incorrect updates.\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('epoch: ', epoch+1, 'loss: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[34.9980],\n",
      "        [39.9977]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# testing on new data    \n",
    "X = torch.Tensor([[7], [8]])\n",
    "predicted = lin_model(X)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
